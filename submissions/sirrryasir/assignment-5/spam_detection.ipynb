{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spam Detection – Logistic Regression, Random Forest & Naive Bayes\n",
                "\n",
                "**Objective:**\n",
                "In this notebook, we implement spam detection using **Logistic Regression**, **Random Forest**, and **Naive Bayes (MultinomialNB)**. We evaluate all three models using Accuracy, Precision, Recall, F1-Score, and Confusion Matrix, and perform sanity checks on sample messages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --------------------------------\n",
                "# 0) Imports\n",
                "# --------------------------------\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
                ")\n",
                "\n",
                "RANDOM_STATE = 42  # reproducibility"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Dataset\n",
                "\n",
                "We use the dataset provided in class (`mail_l7_dataset.csv`). We clean missing values and encode labels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   Category                                            Message\n",
                        "0         1  Go until jurong point, crazy.. Available only ...\n",
                        "1         1                      Ok lar... Joking wif u oni...\n",
                        "2         0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
                        "3         1  U dun say so early hor... U c already then say...\n",
                        "4         1  Nah I don't think he goes to usf, he lives aro...\n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv(\"mail_l7_dataset.csv\")\n",
                "\n",
                "# Basic cleaning: replace NaNs with empty strings (text models can't handle NaN)\n",
                "df = df.where(pd.notnull(df), \"\")\n",
                "\n",
                "# Encode labels: spam -> 0, ham -> 1\n",
                "df[\"Category\"] = df[\"Category\"].str.lower().str.strip().map({\"spam\": 0, \"ham\": 1})\n",
                "\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Split Features & Target\n",
                "\n",
                "We separate the messages (X) from the category labels (y)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df[\"Message\"].astype(str)\n",
                "y = df[\"Category\"].astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Split Data\n",
                "\n",
                "We split the data into 80% training and 20% testing sets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== SPLIT SIZES ===\n",
                        "Train: 4457  | Test: 1115\n"
                    ]
                }
            ],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
                ")\n",
                "\n",
                "print(\"=== SPLIT SIZES ===\")\n",
                "print(\"Train:\", X_train.shape[0], \" | Test:\", X_test.shape[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Text Feature Extraction (TF-IDF)\n",
                "\n",
                "We use **TfidfVectorizer** to convert text messages into numeric feature vectors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== TF-IDF SHAPES ===\n",
                        "X_train: (4457, 7440)  | X_test: (1115, 7440)\n"
                    ]
                }
            ],
            "source": [
                "tfidf = TfidfVectorizer(min_df=1, stop_words=\"english\", lowercase=True)\n",
                "X_train_features = tfidf.fit_transform(X_train)\n",
                "X_test_features  = tfidf.transform(X_test)\n",
                "\n",
                "print(\"\\n=== TF-IDF SHAPES ===\")\n",
                "print(\"X_train:\", X_train_features.shape, \" | X_test:\", X_test_features.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train Models\n",
                "\n",
                "We train three classifiers: **Logistic Regression**, **Random Forest**, and **Naive Bayes (MultinomialNB)**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Logistic Regression\n",
                "lr = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
                "lr.fit(X_train_features, y_train)\n",
                "lr_pred = lr.predict(X_test_features)\n",
                "\n",
                "# Random Forest\n",
                "rf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
                "rf.fit(X_train_features, y_train)\n",
                "rf_pred = rf.predict(X_test_features.toarray())\n",
                "\n",
                "# Naive Bayes (MultinomialNB)\n",
                "nb = MultinomialNB()\n",
                "nb.fit(X_train_features, y_train)\n",
                "nb_pred = nb.predict(X_test_features)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate Performance\n",
                "\n",
                "We use helper functions to print evaluation metrics and confusion matrices for all three models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def print_clf_metrics(name, y_true, y_pred, pos_label=0):\n",
                "    \"\"\"Print Accuracy, Precision, Recall, F1. pos_label=0 means 'spam' is positive.\"\"\"\n",
                "    acc  = accuracy_score(y_true, y_pred)\n",
                "    prec = precision_score(y_true, y_pred, pos_label=pos_label)\n",
                "    rec  = recall_score(y_true, y_pred, pos_label=pos_label)\n",
                "    f1   = f1_score(y_true, y_pred, pos_label=pos_label)\n",
                "    print(f\"\\n{name} Performance:\")\n",
                "    print(f\"  Accuracy : {acc:.3f}\")\n",
                "    print(f\"  Precision: {prec:.3f}\")\n",
                "    print(f\"  Recall   : {rec:.3f}\")\n",
                "    print(f\"  F1-Score : {f1:.3f}\")\n",
                "\n",
                "def print_confmat(name, y_true, y_pred):\n",
                "    \"\"\"\n",
                "    Confusion matrix with readable labels.\n",
                "    Rows = Actual, Cols = Predicted\n",
                "    \"\"\"\n",
                "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
                "    cm_df = pd.DataFrame(\n",
                "        cm,\n",
                "        index   = [\"Actual: Ham (1)\",  \"Actual: Spam (0)\"],\n",
                "        columns = [\"Pred: Ham (1)\",    \"Pred: Spam (0)\"]\n",
                "    )\n",
                "    print(f\"\\n{name} – Confusion Matrix:\\n{cm_df}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Logistic Regression Performance:\n",
                        "  Accuracy : 0.968\n",
                        "  Precision: 1.000\n",
                        "  Recall   : 0.758\n",
                        "  F1-Score : 0.863\n",
                        "\n",
                        "Logistic Regression – Confusion Matrix:\n",
                        "                  Pred: Ham (1)  Pred: Spam (0)\n",
                        "Actual: Ham (1)             966               0\n",
                        "Actual: Spam (0)             36             113\n",
                        "\n",
                        "Random Forest Performance:\n",
                        "  Accuracy : 0.983\n",
                        "  Precision: 1.000\n",
                        "  Recall   : 0.872\n",
                        "  F1-Score : 0.932\n",
                        "\n",
                        "Random Forest – Confusion Matrix:\n",
                        "                  Pred: Ham (1)  Pred: Spam (0)\n",
                        "Actual: Ham (1)             966               0\n",
                        "Actual: Spam (0)             19             130\n",
                        "\n",
                        "Naive Bayes Performance:\n",
                        "  Accuracy : 0.977\n",
                        "  Precision: 1.000\n",
                        "  Recall   : 0.826\n",
                        "  F1-Score : 0.904\n",
                        "\n",
                        "Naive Bayes – Confusion Matrix:\n",
                        "                  Pred: Ham (1)  Pred: Spam (0)\n",
                        "Actual: Ham (1)             966               0\n",
                        "Actual: Spam (0)             26             123\n"
                    ]
                }
            ],
            "source": [
                "# Show results for all three models\n",
                "print_clf_metrics(\"Logistic Regression\", y_test, lr_pred, pos_label=0)\n",
                "print_confmat(\"Logistic Regression\", y_test, lr_pred)\n",
                "\n",
                "print_clf_metrics(\"Random Forest\", y_test, rf_pred, pos_label=0)\n",
                "print_confmat(\"Random Forest\", y_test, rf_pred)\n",
                "\n",
                "print_clf_metrics(\"Naive Bayes\", y_test, nb_pred, pos_label=0)\n",
                "print_confmat(\"Naive Bayes\", y_test, nb_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Sanity Checks\n",
                "\n",
                "We test all three models on **3 specific example messages** and compare their predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== SANITY CHECK ===\n",
                        "Message: \"Free entry in 2 a weekly competition!\"\n",
                        "  LR Prediction : Ham (1)\n",
                        "  RF Prediction : Ham (1)\n",
                        "  NB Prediction : Spam (0)\n",
                        "\n",
                        "=== SANITY CHECK ===\n",
                        "Message: \"I will meet you at the cafe tomorrow\"\n",
                        "  LR Prediction : Ham (1)\n",
                        "  RF Prediction : Ham (1)\n",
                        "  NB Prediction : Ham (1)\n",
                        "\n",
                        "=== SANITY CHECK ===\n",
                        "Message: \"Congratulations, you won a free ticket\"\n",
                        "  LR Prediction : Ham (1)\n",
                        "  RF Prediction : Ham (1)\n",
                        "  NB Prediction : Ham (1)\n"
                    ]
                }
            ],
            "source": [
                "def lab2str(v):\n",
                "    return \"Spam (0)\" if v == 0 else \"Ham (1)\"\n",
                "\n",
                "test_messages = [\n",
                "    \"Free entry in 2 a weekly competition!\",\n",
                "    \"I will meet you at the cafe tomorrow\",\n",
                "    \"Congratulations, you won a free ticket\"\n",
                "]\n",
                "\n",
                "for msg in test_messages:\n",
                "    msg_features = tfidf.transform([msg])\n",
                "\n",
                "    lr_pred_one = int(lr.predict(msg_features)[0])\n",
                "    rf_pred_one = int(rf.predict(msg_features.toarray())[0])\n",
                "    nb_pred_one = int(nb.predict(msg_features)[0])\n",
                "\n",
                "    print(f\"\\n=== SANITY CHECK ===\")\n",
                "    print(f\"Message: \\\"{msg}\\\"\")\n",
                "    print(f\"  LR Prediction : {lab2str(lr_pred_one)}\")\n",
                "    print(f\"  RF Prediction : {lab2str(rf_pred_one)}\")\n",
                "    print(f\"  NB Prediction : {lab2str(nb_pred_one)}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
