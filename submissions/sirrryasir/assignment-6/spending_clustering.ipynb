{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spending Pattern Analysis with K-Means (Clustering)\n",
                "\n",
                "**Objective:**\n",
                "Implement customer spending segmentation using **K-Means** on `Income_$` and `SpendingScore`. Evaluate multiple values of **k** with the Elbow check, choose the best clusters, and evaluate using Silhouette Score and Davies-Bouldin Index (DBI)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --------------------------------\n",
                "# 0) Imports\n",
                "# --------------------------------\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
                "\n",
                "RANDOM_STATE = 42  # For reproducibility"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Dataset\n",
                "\n",
                "We use the `spending_l9_dataset.csv` dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   CustomerID  Age  Income_$  SpendingScore  VisitsPerMonth  OnlinePurchases  \\\n",
                        "0           1   28        33             78              14                9   \n",
                        "1           2   21        25             87               8               23   \n",
                        "2           3   23        24             88              13               10   \n",
                        "3           4   24        25             73              16               11   \n",
                        "4           5   20        23             88              17               16   \n",
                        "\n",
                        "   Gender Region  \n",
                        "0  Female   East  \n",
                        "1    Male  North  \n",
                        "2    Male  South  \n",
                        "3  Female   West  \n",
                        "4    Male   West  \n"
                    ]
                }
            ],
            "source": [
                "df = pd.read_csv(\"spending_l9_dataset.csv\")\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Features\n",
                "\n",
                "We select `Income_$` and `SpendingScore`, fill any missing values with the median, and apply `StandardScaler` to ensure K-Means computes distances fairly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Scaled shape: (200, 2)\n"
                    ]
                }
            ],
            "source": [
                "FEATURES = [\"Income_$\", \"SpendingScore\"]\n",
                "X = df[FEATURES].copy()\n",
                "\n",
                "# Fill missing numeric values with median (if any)\n",
                "for col in FEATURES:\n",
                "    if X[col].isna().any():\n",
                "        X[col] = X[col].fillna(X[col].median())\n",
                "\n",
                "# Scale features\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "print(\"Scaled shape:\", X_scaled.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Elbow Check (SSE)\n",
                "\n",
                "We calculate the Sum of Squared Errors (SSE) for $k$ values from 1 to 10 to find the \"elbow point\" where improvements slow down."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== ELBOW METHOD (SSE per k) ===\n",
                        "k=1 → SSE=400.00\n",
                        "k=2 → SSE=199.70\n",
                        "k=3 → SSE=79.37\n",
                        "k=4 → SSE=21.37\n",
                        "k=5 → SSE=19.09\n",
                        "k=6 → SSE=15.65\n",
                        "k=7 → SSE=14.48\n",
                        "k=8 → SSE=13.81\n",
                        "k=9 → SSE=12.94\n",
                        "k=10 → SSE=11.52\n"
                    ]
                }
            ],
            "source": [
                "print(\"=== ELBOW METHOD (SSE per k) ===\")\n",
                "for k in range(1, 11):\n",
                "    km = KMeans(n_clusters=k, n_init=\"auto\", random_state=RANDOM_STATE)\n",
                "    km.fit(X_scaled)\n",
                "    print(f\"k={k} → SSE={km.inertia_:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Training (Pick K)\n",
                "\n",
                "Based on the SSE drop, the \"elbow\" forms at **K=5** (the SSE explicitly flattens significantly between 5 and 6). We fit our final model with 5 clusters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "K = 5\n",
                "kmeans = KMeans(n_clusters=K, n_init=\"auto\", random_state=RANDOM_STATE)\n",
                "labels = kmeans.fit_predict(X_scaled)\n",
                "\n",
                "# Add the predicted cluster back to the dataframe\n",
                "df[\"Cluster\"] = labels.astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluate Clustering\n",
                "\n",
                "We compute the **Silhouette Score** (closer to 1 is better) and the **Davies–Bouldin Index** (closer to 0 is better)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== METRICS ===\n",
                        "Silhouette Score : 0.642\n",
                        "Davies–Bouldin   : 0.571\n"
                    ]
                }
            ],
            "source": [
                "sil = silhouette_score(X_scaled, labels)\n",
                "dbi = davies_bouldin_score(X_scaled, labels)\n",
                "print(\"=== METRICS ===\")\n",
                "print(f\"Silhouette Score : {sil:.3f}\")\n",
                "print(f\"Davies–Bouldin   : {dbi:.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Cluster Centers (Original Units)\n",
                "\n",
                "Since our model was trained on scaled data, we inverse-transform the cluster centers to see their actual values in `Income_$` and `SpendingScore`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== CLUSTER CENTERS (Original Units) ===\n",
                        "         Income_$  SpendingScore\n",
                        "Cluster                         \n",
                        "0           56.32          53.58\n",
                        "1           28.92          19.60\n",
                        "2           25.33          78.04\n",
                        "3           99.16          79.24\n",
                        "4           22.74          89.04\n"
                    ]
                }
            ],
            "source": [
                "centers_scaled = kmeans.cluster_centers_\n",
                "centers_original = scaler.inverse_transform(centers_scaled)\n",
                "\n",
                "centers_df = pd.DataFrame(centers_original, columns=FEATURES)\n",
                "centers_df.index.name = \"Cluster\"\n",
                "\n",
                "print(\"=== CLUSTER CENTERS (Original Units) ===\")\n",
                "print(centers_df.round(2))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Sanity Check\n",
                "\n",
                "We print off 3 random customer samples to see their values and their assigned cluster."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "=== SANITY CHECK ===\n",
                        "     Income_$  SpendingScore  Cluster\n",
                        "15         19             86        4\n",
                        "62         68             51        0\n",
                        "114        43             14        1\n"
                    ]
                }
            ],
            "source": [
                "sample_idx = [15, 62, 114]\n",
                "sanity = df.loc[sample_idx, FEATURES + [\"Cluster\"]]\n",
                "print(\"\\n=== SANITY CHECK ===\")\n",
                "print(sanity)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save Output\n",
                "\n",
                "Exported the final labeled data to a CSV file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Saved labeled clusters to: spending_labeled_clusters.csv\n"
                    ]
                }
            ],
            "source": [
                "OUT_PATH = \"spending_labeled_clusters.csv\"\n",
                "df.to_csv(OUT_PATH, index=False)\n",
                "print(f\"\\nSaved labeled clusters to: {OUT_PATH}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
