{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a5c72c-b865-4ebd-bfdc-bf0c50fd6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6a7851-b522-451d-969e-3f7d9b9ae6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file using pandas\n",
    "df= pd.read_csv('mail_l7_dataset.csv')\n",
    "df.head()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d0fd1f-2ad8-4f9b-ab89-1abedd96ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category                                            Message\n",
      "0         1  Go until jurong point, crazy.. Available only ...\n",
      "1         1                      Ok lar... Joking wif u oni...\n",
      "2         0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         1  U dun say so early hor... U c already then say...\n",
      "4         1  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# label Encoding\n",
    "df[\"Category\"]= df[\"Category\"].str.lower().str.strip().map({ \"spam\": 0, \"ham\" : 1})\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311e66b5-56ab-47e2-b3ea-4fc92dd656f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[\"Message\"].astype(str)\n",
    "y = df[\"Category\"].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d50739-6473-48c3-8816-bc2aff701705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== SPLIT SIZE ==\n",
      "Train Data: 4457  | Test Data: 1115\n"
     ]
    }
   ],
   "source": [
    " # Split Data trainning 80% and tests 20%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"== SPLIT SIZE ==\")\n",
    "print(\"Train Data:\", X_train.shape[0], \" | Test Data:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a822cd0-3353-4a1e-af9d-3ca26f98e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "vectorizer = TfidfVectorizer(min_df=1, stop_words=\"english\", lowercase=True)\n",
    "\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features  = vectorizer.transform(X_test)   # muhiim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad56ccba-81c8-4fb7-81c8-1cfab374eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LR prediction\n",
       "1                1002\n",
       "0                 113\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model using logistic regression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "lr.fit(X_train_features, y_train)\n",
    "\n",
    "lr_predict = lr.predict(X_test_features)\n",
    "print(lr_predict)\n",
    "#print(lr.predict(X_test_features))\n",
    "lr_pred_df = pd.DataFrame(lr_predict, columns=[\"LR prediction\"])\n",
    "# lr_pred_df.head(30)\n",
    "lr_pred_df.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e0e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57edfdf-1a33-49a8-9646-777526d53f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RF prediction\n",
       "1                985\n",
       "0                130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model by using a RandomForest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "# fit the model\n",
    "rf.fit(X_train_features, y_train)\n",
    "# pridect the model\n",
    "rf_pred = rf.predict(X_test_features)  \n",
    "# convert the predictions of the RandomForest Classifier model to a DataFrame\n",
    "rf_pred_df = pd.DataFrame(rf_pred, columns=[\"RF prediction\"])\n",
    "# rf_pred_df.head(30)\n",
    "rf_pred_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac54a4bd-0082-4a0f-b399-76af7571daea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np prediction\n",
       "1                992\n",
       "0                123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model by using Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "# fit the model\n",
    "nb.fit(X_train_features,y_train)\n",
    "# pridect the model\n",
    "nb_pred = nb.predict(X_test_features)\n",
    "# convert the predictions of the Naive Bayes model to a DataFrame\n",
    "nb_pred_df = pd.DataFrame(nb_pred, columns=[\"np prediction\"])\n",
    "nb_pred_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58c03e89-97a2-4625-8a51-d7e3bf72f6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy (Overall): 0.9677\n",
      "Precision (pos=0): 1.0000\n",
      "Recall (pos=0):    0.7584\n",
      "F1-Score (pos=0):  0.8626\n",
      "\n",
      "Logistic Regression Confusion Matrix (labels (0, 1)):\n",
      "                 Pred 0 (Spam)  Pred 1 (Ham)\n",
      "Actual 0 (Spam)            113            36\n",
      "Actual 1 (Ham)               0           966\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy (Overall): 0.9830\n",
      "Precision (pos=0): 1.0000\n",
      "Recall (pos=0):    0.8725\n",
      "F1-Score (pos=0):  0.9319\n",
      "\n",
      "Random Forest Confusion Matrix (labels (0, 1)):\n",
      "                 Pred 0 (Spam)  Pred 1 (Ham)\n",
      "Actual 0 (Spam)            130            19\n",
      "Actual 1 (Ham)               0           966\n",
      "\n",
      "Naive Bayes Performance:\n",
      "Accuracy (Overall): 0.9767\n",
      "Precision (pos=0): 1.0000\n",
      "Recall (pos=0):    0.8255\n",
      "F1-Score (pos=0):  0.9044\n",
      "\n",
      "Naive Bayes Confusion Matrix (labels (0, 1)):\n",
      "                 Pred 0 (Spam)  Pred 1 (Ham)\n",
      "Actual 0 (Spam)            123            26\n",
      "Actual 1 (Ham)               0           966\n"
     ]
    }
   ],
   "source": [
    "def display_metrics(model_name, y_actual, y_pred, pos_label=0):\n",
    "    accuracy = accuracy_score(y_actual, y_pred)\n",
    "\n",
    "    precision = precision_score(\n",
    "        y_actual, y_pred, pos_label=pos_label, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    recall = recall_score(\n",
    "        y_actual, y_pred, pos_label=pos_label, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    f1 = f1_score(\n",
    "        y_actual, y_pred, pos_label=pos_label, average=\"binary\", zero_division=0\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Accuracy (Overall): {accuracy:.4f}\")\n",
    "    print(f\"Precision (pos={pos_label}): {precision:.4f}\")\n",
    "    print(f\"Recall (pos={pos_label}):    {recall:.4f}\")\n",
    "    print(f\"F1-Score (pos={pos_label}):  {f1:.4f}\")\n",
    "\n",
    "# Displaying the Confusion matrix\n",
    "def show_confusion_matrix(model_name, y_actual, y_pred, labels_order=(0, 1)):\n",
    "    cm = confusion_matrix(y_actual, y_pred, labels=list(labels_order))\n",
    "\n",
    "    # labels_order = (0,1) means: row/col0 is Spam(0), row/col1 is Ham(1)\n",
    "    index_names = [f\"Actual {labels_order[0]} (Spam)\", f\"Actual {labels_order[1]} (Ham)\"]\n",
    "    col_names   = [f\"Pred {labels_order[0]} (Spam)\",  f\"Pred {labels_order[1]} (Ham)\"]\n",
    "\n",
    "    cm_df = pd.DataFrame(cm, index=index_names, columns=col_names)\n",
    "\n",
    "    print(f\"\\n{model_name} Confusion Matrix (labels {labels_order}):\")\n",
    "    print(cm_df)\n",
    "\n",
    "# Evaluate models\n",
    "display_metrics(\"Logistic Regression\", y_test, lr_predict, pos_label=0)\n",
    "show_confusion_matrix(\"Logistic Regression\", y_test, lr_predict, labels_order=(0, 1))\n",
    "\n",
    "display_metrics(\"Random Forest\", y_test, rf_pred, pos_label=0)\n",
    "show_confusion_matrix(\"Random Forest\", y_test, rf_pred, labels_order=(0, 1))\n",
    "\n",
    "display_metrics(\"Naive Bayes\", y_test, nb_pred, pos_label=0)\n",
    "show_confusion_matrix(\"Naive Bayes\", y_test, nb_pred, labels_order=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "212af640-0402-428a-aad2-e6ed59f1aade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE MESSAGE PREDICTIONS ===\n",
      "\n",
      "Sample Message: Congratulations! You've won a free prize!\n",
      "LR pred: Spam (0)\n",
      "RF pred: Ham (1)\n",
      "NB pred: Spam (0)\n",
      "\n",
      "\n",
      "Sample Message: You're invited to claim your free reward!\n",
      "LR pred: Spam (0)\n",
      "RF pred: Ham (1)\n",
      "NB pred: Spam (0)\n",
      "\n",
      "\n",
      "Sample Message: You’ve been selected for a chance to win big!\n",
      "LR pred: Ham (1)\n",
      "RF pred: Ham (1)\n",
      "NB pred: Ham (1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sanity check (for the Sample Message)\n",
    "sample_message = [\n",
    "    \"Congratulations! You've won a free prize!\",\n",
    "    \"You're invited to claim your free reward!\",\n",
    "    \"You’ve been selected for a chance to win big!\",\n",
    "]\n",
    "\n",
    "# this function will change the label output to string like: 1-> ham and 0-> spam\n",
    "def label_to_str(r):\n",
    " return \"Spam (0)\" if r == 0 else \"Ham (1)\"\n",
    "\n",
    "\n",
    "print(\"\\n=== SAMPLE MESSAGE PREDICTIONS ===\")\n",
    "for i in sample_message:\n",
    " lr_pred_sample = int(lr.predict(vectorizer.transform([i]))[0])\n",
    " rf_pred_sample = int(rf.predict(vectorizer.transform([i]))[0])\n",
    " nb_pred_sample = int(nb.predict(vectorizer.transform([i]))[0])\n",
    " #\n",
    " print(f\"\\nSample Message: {i}\")\n",
    " print(f\"LR pred: {label_to_str(lr_pred_sample)}\") \n",
    " print(f\"RF pred: {label_to_str(rf_pred_sample)}\")\n",
    " print(f\"NB pred: {label_to_str(nb_pred_sample)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d98ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
